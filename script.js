// script.js - ThamAI Settings Pro+
// expects backend endpoints: /chat, /whisper, /speak
const API_BASE = "https://thamai-backend-new.onrender.com"; // update if needed

// DOM
const chatBox = document.getElementById("chat-box");
const userInput = document.getElementById("user-input");
const sendBtn = document.getElementById("send-btn");
const clearBtn = document.getElementById("clear-btn");
const recordBtn = document.getElementById("record-btn");
const speakBtn = document.getElementById("speak-btn");
const audioPlayer = document.getElementById("audio-player");

const settingsBtn = document.getElementById("settings-btn");
const settingsModal = document.getElementById("settings-modal");
const closeSettings = document.getElementById("close-settings");
const saveSettingsBtn = document.getElementById("save-settings");
const testVoiceBtn = document.getElementById("test-voice");
const resetSettingsBtn = document.getElementById("reset-settings");

const genderSelect = document.getElementById("gender-select");
const langSelect = document.getElementById("lang-select");
const rateInput = document.getElementById("rate");
const pitchInput = document.getElementById("pitch");
const rateVal = document.getElementById("rate-val");
const pitchVal = document.getElementById("pitch-val");
const toggleVisual = document.getElementById("toggle-visual");
const toggleAvatar = document.getElementById("toggle-avatar");

const avatarEl = document.getElementById("avatar");
const vizCanvas = document.getElementById("vizCanvas");

// state
let mediaRecorder = null;
let audioChunks = [];
let lastBotReply = "";
let audioCtx = null;
let analyser = null;
let vizAnimationId = null;
let micStream = null;

// default settings
const DEFAULTS = {
  gender: "female", lang: "vi", rate: 1.0, pitch: 1.0,
  showVisual: true, showAvatar: true
};

function loadSettings(){
  try {
    const raw = localStorage.getItem("thamai_settings_v1");
    if (!raw) return DEFAULTS;
    const parsed = JSON.parse(raw);
    return {...DEFAULTS, ...parsed};
  } catch (e) {
    console.error("loadSettings error:", e);
    return DEFAULTS;
  }
}

function saveSettings(obj){
  localStorage.setItem("thamai_settings_v1", JSON.stringify(obj));
}

function applySettingsToUI(s){
  genderSelect.value = s.gender;
  langSelect.value = s.lang;
  rateInput.value = s.rate;
  pitchInput.value = s.pitch;
  rateVal.textContent = s.rate;
  pitchVal.textContent = s.pitch;
  toggleVisual.checked = !!s.showVisual;
  toggleAvatar.checked = !!s.showAvatar;
  vizCanvas.style.display = s.showVisual ? "block" : "none";
  avatarEl.style.display = s.showAvatar ? "block" : "none";
}

let settings = loadSettings();
applySettingsToUI(settings);

// settings modal
settingsBtn.addEventListener("click", ()=> settingsModal.classList.remove("hidden"));
closeSettings.addEventListener("click", ()=> settingsModal.classList.add("hidden"));

rateInput.addEventListener("input", ()=> rateVal.textContent = rateInput.value);
pitchInput.addEventListener("input", ()=> pitchVal.textContent = pitchInput.value);

saveSettingsBtn.addEventListener("click", ()=>{
  settings = {
    gender: genderSelect.value,
    lang: langSelect.value,
    rate: parseFloat(rateInput.value),
    pitch: parseFloat(pitchInput.value),
    showVisual: toggleVisual.checked,
    showAvatar: toggleAvatar.checked
  };
  saveSettings(settings);
  applySettingsToUI(settings);
  appendMessage("bot", "âœ… LÆ°u cÃ i Ä‘áº·t thÃ nh cÃ´ng.");
  settingsModal.classList.add("hidden");
});

resetSettingsBtn.addEventListener("click", ()=>{
  settings = DEFAULTS;
  saveSettings(settings);
  applySettingsToUI(settings);
  appendMessage("bot", "ðŸ”„ ÄÃ£ Ä‘áº·t láº¡i cÃ i Ä‘áº·t máº·c Ä‘á»‹nh.");
});

testVoiceBtn.addEventListener("click", async ()=>{
  const sample = settings.lang === "en" ? "Hello, this is ThamAI speaking." : "Xin chÃ o, Ä‘Ã¢y lÃ  Tháº¡chAI. TÃ´i Ä‘ang thá»­ giá»ng.";
  // Use /speak to test TTS on backend
  try {
    const res = await fetch(`${API_BASE}/speak`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ text: sample, gender: settings.gender })
    });
    if (!res.ok) {
      const t = await res.text(); console.error("TTS HTTP error:", res.status, t);
      appendMessage("bot","âš ï¸ Lá»—i khi thá»­ giá»ng.");
      return;
    }
    const blob = await res.blob();
    const url = URL.createObjectURL(blob);
    playAudioUrl(url);
  } catch (e) {
    console.error("testVoice failed:", e);
    appendMessage("bot","âš ï¸ Lá»—i khi gá»i TTS thá»­ giá»ng.");
  }
});

// ---- Chat logic ----
sendBtn.addEventListener("click", sendMessage);
clearBtn.addEventListener("click", ()=>{ chatBox.innerHTML = ""; });

userInput.addEventListener("keypress", (e)=>{
  if (e.key === "Enter" && !e.shiftKey) { e.preventDefault(); sendBtn.click(); }
});

async function sendMessage(){
  const text = userInput.value.trim();
  if (!text) return;
  appendMessage("user", text);
  userInput.value = "";
  try {
    const res = await fetch(`${API_BASE}/chat`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ message: text })
    });
    if (!res.ok) {
      const t = await res.text(); console.error("/chat HTTP:", res.status, t);
      appendMessage("bot", "âš ï¸ Lá»—i khi gá»i /chat.");
      return;
    }
    const data = await res.json();
    if (data.reply) {
      appendMessage("bot", data.reply);
      lastBotReply = data.reply;
    } else {
      appendMessage("bot", "âŒ Pháº£n há»“i /chat khÃ´ng Ä‘Ãºng.");
      console.error("chat unexpected:", data);
    }
  } catch (e) {
    console.error("chat fetch failed:", e);
    appendMessage("bot", "âš ï¸ KhÃ´ng thá»ƒ káº¿t ná»‘i server /chat.");
  }
}

// ---- Recording / Whisper ----
recordBtn.addEventListener("click", async ()=>{
  if (mediaRecorder && mediaRecorder.state === "recording") {
    // stop
    mediaRecorder.stop();
    recordBtn.textContent = "ðŸŽ¤ Ghi Ã¢m";
    stopMicVisualizer();
    return;
  }

  // start recording
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    micStream = stream;
    // start mic visualizer
    if (settings.showVisual) startMicVisualizer(stream);

    // pick supported mime
    let mime = "";
    if (MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) mime = "audio/webm;codecs=opus";
    else if (MediaRecorder.isTypeSupported("audio/webm")) mime = "audio/webm";
    else if (MediaRecorder.isTypeSupported("audio/wav")) mime = "audio/wav";

    mediaRecorder = new MediaRecorder(stream, mime ? { mimeType: mime } : undefined);
    audioChunks = [];

    mediaRecorder.ondataavailable = e => { if (e.data && e.data.size>0) audioChunks.push(e.data); };

    mediaRecorder.onstop = async ()=>{
      // assemble blob
      const blob = new Blob(audioChunks, { type: audioChunks[0]?.type || "audio/webm" });
      const fd = new FormData();
      fd.append("file", blob, "recording.webm"); // backend expects 'file'
      appendMessage("user","ðŸŽ™ï¸ (Äang gá»­i file ghi Ã¢m...)");

      try {
        const res = await fetch(`${API_BASE}/whisper`, { method: "POST", body: fd });
        if (!res.ok) {
          const txt = await res.text();
          console.error("Whisper HTTP error:", res.status, txt);
          appendMessage("bot", `âš ï¸ Whisper lá»—i HTTP (${res.status}).`);
          return;
        }
        const data = await res.json();
        if (data.text) {
          appendMessage("user", "ðŸ—£ï¸ " + data.text);
          userInput.value = data.text;
        } else {
          appendMessage("bot", "âŒ KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c giá»ng nÃ³i.");
          console.error("whisper unexpected:", data);
        }
      } catch (err) {
        console.error("Whisper fetch failed:", err);
        appendMessage("bot", "âš ï¸ Lá»—i khi gá»­i file ghi Ã¢m.");
      } finally {
        // cleanup mic
        if (micStream) { micStream.getTracks().forEach(t=>t.stop()); micStream = null; }
        stopMicVisualizer();
      }
    };

    mediaRecorder.start();
    recordBtn.textContent = "â¹ï¸ Dá»«ng";
    appendMessage("bot","ðŸ”´ Äang ghi Ã¢m â€” báº¥m láº¡i Ä‘á»ƒ dá»«ng.");
  } catch (err) {
    console.error("getUserMedia error:", err);
    appendMessage("bot","âš ï¸ KhÃ´ng thá»ƒ truy cáº­p micro. Kiá»ƒm tra quyá»n trÃ¬nh duyá»‡t.");
  }
});

// ---- TTS speak: call backend /speak (passes gender + text) ----
speakBtn.addEventListener("click", async ()=>{
  const text = lastBotReply || userInput.value.trim();
  if (!text) { alert("ChÆ°a cÃ³ ná»™i dung Ä‘á»ƒ ThamAI nÃ³i."); return; }

  try {
    const res = await fetch(`${API_BASE}/speak`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ text, gender: settings.gender })
    });
    if (!res.ok) {
      const t = await res.text(); console.error("TTS HTTP error:", res.status, t);
      appendMessage("bot","âš ï¸ Lá»—i khi yÃªu cáº§u phÃ¡t Ã¢m thanh.");
      return;
    }
    const blob = await res.blob();
    if (!blob.type.startsWith("audio")) {
      const txt = await blob.text();
      console.error("TTS not audio:", txt);
      appendMessage("bot","âš ï¸ Server chÆ°a tráº£ vá» Ã¢m thanh há»£p lá»‡.");
      return;
    }
    const url = URL.createObjectURL(blob);
    playAudioUrl(url);
  } catch (err) {
    console.error("TTS fetch failed:", err);
    appendMessage("bot","âš ï¸ KhÃ´ng thá»ƒ phÃ¡t Ã¢m thanh (lá»—i máº¡ng).");
  }
});

// play audio and visualize & avatar animate
async function playAudioUrl(url){
  try {
    stopPlaybackVisualizer();
    audioPlayer.hidden = false;
    audioPlayer.src = url;
    await audioPlayer.play();
    // setup visualizer on audio element
    if (settings.showVisual) startPlaybackVisualizer(audioPlayer);
    if (settings.showAvatar) startAvatarSpeaking();
    audioPlayer.onended = ()=> { stopPlaybackVisualizer(); stopAvatarSpeaking(); };
  } catch (e) {
    console.error("playAudioUrl:", e);
  }
}

// ---- visualizer utilities ----
function createAudioContextIfNeeded(){
  if (!audioCtx) {
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  }
}

function startMicVisualizer(stream){
  try {
    createAudioContextIfNeeded();
    stopMicVisualizer();
    const src = audioCtx.createMediaStreamSource(stream);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 1024;
    src.connect(analyser);
    drawVisualizer();
  } catch (e) {
    console.warn("startMicVisualizer failed:", e);
  }
}

function startPlaybackVisualizer(audioEl){
  try {
    createAudioContextIfNeeded();
    stopPlaybackVisualizer();
    const src = audioCtx.createMediaElementSource(audioEl);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 1024;
    src.connect(analyser);
    analyser.connect(audioCtx.destination);
    drawVisualizer();
  } catch (e) {
    console.warn("startPlaybackVisualizer failed:", e);
  }
}

function stopMicVisualizer(){ stopVisualizer(); }
function stopPlaybackVisualizer(){ stopVisualizer(); }

function stopVisualizer(){
  if (vizAnimationId) cancelAnimationFrame(vizAnimationId);
  vizAnimationId = null;
  if (analyser) { analyser.disconnect(); analyser = null; }
}

function drawVisualizer(){
  if (!analyser) return;
  const canvas = vizCanvas;
  const ctx = canvas.getContext("2d");
  canvas.width = canvas.clientWidth * devicePixelRatio;
  canvas.height = canvas.clientHeight * devicePixelRatio;
  const bufferLen = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLen);

  function draw(){
    vizAnimationId = requestAnimationFrame(draw);
    analyser.getByteTimeDomainData(dataArray);
    ctx.fillStyle = "#021827";
    ctx.fillRect(0,0,canvas.width,canvas.height);
    ctx.lineWidth = 2 * devicePixelRatio;
    ctx.strokeStyle = "rgba(96,165,250,0.9)";
    ctx.beginPath();
    const sliceWidth = canvas.width / bufferLen;
    let x = 0;
    for (let i=0;i<bufferLen;i++){
      const v = dataArray[i] / 128.0;
      const y = (v * canvas.height/2);
      if (i===0) ctx.moveTo(x,y);
      else ctx.lineTo(x,y);
      x += sliceWidth;
    }
    ctx.lineTo(canvas.width, canvas.height/2);
    ctx.stroke();
  }
  draw();
}

// ---- avatar speak animation ----
let avatarTimer = null;
function startAvatarSpeaking(){
  avatarEl.classList.add("speaking");
  // small mouth ry randomization
  avatarTimer = setInterval(()=> {
    const mouth = avatarEl.querySelector("#mouth ellipse");
    if (mouth) {
      const ry = 7 + Math.random()*12;
      mouth.setAttribute("ry", ry);
    }
    // occasional eye blink while speaking
    const eyes = avatarEl.querySelectorAll("#eyes ellipse");
    if (Math.random() < 0.12) {
      eyes.forEach(e=> e.setAttribute("ry", 1));
      setTimeout(()=> eyes.forEach(e=> e.setAttribute("ry",6)), 120);
    }
  }, 120);
}
function stopAvatarSpeaking(){
  avatarEl.classList.remove("speaking");
  if (avatarTimer) { clearInterval(avatarTimer); avatarTimer = null; }
  // restore mouth
  const mouth = avatarEl.querySelector("#mouth ellipse");
  if (mouth) mouth.setAttribute("ry", 7);
  // restore eyes
  const eyes = avatarEl.querySelectorAll("#eyes ellipse");
  eyes.forEach(e=> e.setAttribute("ry",6));
}

// ---- small helpers ----
function appendMessage(sender, text){
  const div = document.createElement("div");
  div.className = `message ${sender}`;
  div.textContent = text;
  chatBox.appendChild(div);
  chatBox.scrollTop = chatBox.scrollHeight;
}

// check backend on load
(async function checkBackend(){
  try {
    const res = await fetch(`${API_BASE}/test`);
    // sometimes server returns HTML error page (unexpected token '<')
    const contentType = res.headers.get("Content-Type") || "";
    if (!res.ok) {
      const txt = await res.text();
      console.error("backend /test error:", res.status, txt);
      appendMessage("bot","âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i backend (HTTP "+res.status+")");
      return;
    }
    if (contentType.includes("application/json")){
      const data = await res.json();
      if (data.status === "ok") appendMessage("bot","âœ… Káº¿t ná»‘i backend ThamAI thÃ nh cÃ´ng!");
      else appendMessage("bot","âš ï¸ Backend pháº£n há»“i khÃ´ng Ä‘Ãºng.");
    } else {
      const txt = await res.text();
      console.warn("backend /test returned non-json:", txt);
      appendMessage("bot","âš ï¸ Backend tráº£ vá» ná»™i dung khÃ´ng pháº£i JSON.");
    }
  } catch (e) {
    console.error("checkBackend:", e);
    appendMessage("bot","âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i tá»›i mÃ¡y chá»§ backend.");
  }
})();
